{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from bpemb import BPEmb\n",
    "from tqdm import tqdm\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question_text_tokenized</th>\n",
       "      <th>document_plaintext_tokenized</th>\n",
       "      <th>answer_text_tokenized</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was quantum field theory developed?</td>\n",
       "      <td>Quantum field theory</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': array([159]), 'answer_text': ...</td>\n",
       "      <td>Quantum field theory naturally began with the ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum%20field%...</td>\n",
       "      <td>[159]</td>\n",
       "      <td>['1920s']</td>\n",
       "      <td>['when', 'was', 'quantum', 'field', 'theory', ...</td>\n",
       "      <td>['quantum', 'field', 'theory', 'naturally', 'b...</td>\n",
       "      <td>['1920s']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first Nobel prize winner for Liter...</td>\n",
       "      <td>List of Nobel laureates in Literature</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': array([610]), 'answer_text': ...</td>\n",
       "      <td>The Nobel Prize in Literature (Swedish: Nobelp...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20Nobe...</td>\n",
       "      <td>[610]</td>\n",
       "      <td>['Sully Prudhomme']</td>\n",
       "      <td>['who', 'was', 'the', 'first', 'nobel', 'prize...</td>\n",
       "      <td>['the', 'nobel', 'prize', 'in', 'literature', ...</td>\n",
       "      <td>['sully', 'prudhomme']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the dialectical method used?</td>\n",
       "      <td>Dialectic</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': array([129]), 'answer_text': ...</td>\n",
       "      <td>Dialectic or dialectics (Greek: διαλεκτική, di...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dialectic</td>\n",
       "      <td>[129]</td>\n",
       "      <td>['discourse between two or more people holding...</td>\n",
       "      <td>['when', 'is', 'the', 'dialectical', 'method',...</td>\n",
       "      <td>['dialectic', 'or', 'dialectics', '(', 'greek'...</td>\n",
       "      <td>['discourse', 'between', 'two', 'or', 'more', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who invented Hangul?</td>\n",
       "      <td>Origin of Hangul</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': array([88]), 'answer_text': a...</td>\n",
       "      <td>Hangul was personally created and promulgated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Origin%20of%20Ha...</td>\n",
       "      <td>[88]</td>\n",
       "      <td>['Sejong the Great']</td>\n",
       "      <td>['who', 'invented', 'hangul', '?']</td>\n",
       "      <td>['hangul', 'was', 'personally', 'created', 'an...</td>\n",
       "      <td>['sejong', 'the', 'great']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do Grasshoppers eat?</td>\n",
       "      <td>Grasshopper</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': array([0]), 'answer_text': ar...</td>\n",
       "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Grasshopper</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Grasshoppers are plant-eaters, with a few sp...</td>\n",
       "      <td>['what', 'do', 'grasshoppers', 'eat', '?']</td>\n",
       "      <td>['grasshoppers', 'are', 'plant-eaters', ',', '...</td>\n",
       "      <td>['grasshoppers', 'are', 'plant-eaters', ',', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0           When was quantum field theory developed?   \n",
       "1  Who was the first Nobel prize winner for Liter...   \n",
       "2               When is the dialectical method used?   \n",
       "3                               Who invented Hangul?   \n",
       "4                          What do Grasshoppers eat?   \n",
       "\n",
       "                          document_title language  \\\n",
       "0                   Quantum field theory  english   \n",
       "1  List of Nobel laureates in Literature  english   \n",
       "2                              Dialectic  english   \n",
       "3                       Origin of Hangul  english   \n",
       "4                            Grasshopper  english   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  {'answer_start': array([159]), 'answer_text': ...   \n",
       "1  {'answer_start': array([610]), 'answer_text': ...   \n",
       "2  {'answer_start': array([129]), 'answer_text': ...   \n",
       "3  {'answer_start': array([88]), 'answer_text': a...   \n",
       "4  {'answer_start': array([0]), 'answer_text': ar...   \n",
       "\n",
       "                                  document_plaintext  \\\n",
       "0  Quantum field theory naturally began with the ...   \n",
       "1  The Nobel Prize in Literature (Swedish: Nobelp...   \n",
       "2  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
       "3  Hangul was personally created and promulgated ...   \n",
       "4  Grasshoppers are plant-eaters, with a few spec...   \n",
       "\n",
       "                                        document_url answer_start  \\\n",
       "0  https://en.wikipedia.org/wiki/Quantum%20field%...        [159]   \n",
       "1  https://en.wikipedia.org/wiki/List%20of%20Nobe...        [610]   \n",
       "2            https://en.wikipedia.org/wiki/Dialectic        [129]   \n",
       "3  https://en.wikipedia.org/wiki/Origin%20of%20Ha...         [88]   \n",
       "4          https://en.wikipedia.org/wiki/Grasshopper          [0]   \n",
       "\n",
       "                                         answer_text  \\\n",
       "0                                          ['1920s']   \n",
       "1                                ['Sully Prudhomme']   \n",
       "2  ['discourse between two or more people holding...   \n",
       "3                               ['Sejong the Great']   \n",
       "4  ['Grasshoppers are plant-eaters, with a few sp...   \n",
       "\n",
       "                             question_text_tokenized  \\\n",
       "0  ['when', 'was', 'quantum', 'field', 'theory', ...   \n",
       "1  ['who', 'was', 'the', 'first', 'nobel', 'prize...   \n",
       "2  ['when', 'is', 'the', 'dialectical', 'method',...   \n",
       "3                 ['who', 'invented', 'hangul', '?']   \n",
       "4         ['what', 'do', 'grasshoppers', 'eat', '?']   \n",
       "\n",
       "                        document_plaintext_tokenized  \\\n",
       "0  ['quantum', 'field', 'theory', 'naturally', 'b...   \n",
       "1  ['the', 'nobel', 'prize', 'in', 'literature', ...   \n",
       "2  ['dialectic', 'or', 'dialectics', '(', 'greek'...   \n",
       "3  ['hangul', 'was', 'personally', 'created', 'an...   \n",
       "4  ['grasshoppers', 'are', 'plant-eaters', ',', '...   \n",
       "\n",
       "                               answer_text_tokenized  labels  \n",
       "0                                          ['1920s']       1  \n",
       "1                             ['sully', 'prudhomme']       1  \n",
       "2  ['discourse', 'between', 'two', 'or', 'more', ...       1  \n",
       "3                         ['sejong', 'the', 'great']       1  \n",
       "4  ['grasshoppers', 'are', 'plant-eaters', ',', '...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training data\n",
    "dft_eng = pd.read_csv('../../data/dft_eng.csv')\n",
    "dft_jap = pd.read_csv('../../data/dft_jap.csv')\n",
    "dft_fin = pd.read_csv('../../data/dft_fin.csv')\n",
    "\n",
    "# import validation data\n",
    "dfv_eng = pd.read_csv('../../data/dfv_eng.csv')\n",
    "dfv_jap = pd.read_csv('../../data/dfv_jap.csv')\n",
    "dfv_fin = pd.read_csv('../../data/dfv_fin.csv')\n",
    "\n",
    "#import word count\n",
    "word_count = pd.read_csv('../../data/question_word_count.csv')\n",
    "\n",
    "dft_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load english model with 25k word-pieces\n",
    "bpemb_en = BPEmb(lang='en', dim=100, vs=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bpemb_features(dataset, bpemb):\n",
    "  # With bpemb we can tokenize and embed an entire document using .embed(x)\n",
    "  X = [bpemb.embed(x).mean(0) for x in (dataset.document_plaintext)]\n",
    "  y = dataset.labels\n",
    " \n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train = get_bpemb_features(dft_eng, bpemb_en)\n",
    "X_test,y_test = get_bpemb_features(dfv_eng, bpemb_en)\n",
    "lr_bpemb = LogisticRegression(penalty='l2', max_iter=1000, multi_class='multinomial')\n",
    "lr_bpemb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_bpemb = lr_bpemb.predict(X_test)\n",
    "preds_valid_bpemb = lr_bpemb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708061</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.681342</td>\n",
       "      <td>495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679849</td>\n",
       "      <td>0.729293</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.692929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.693955</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.692523</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.693955</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.692523</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.708061  0.656566  0.681342  495.000000\n",
       "1              0.679849  0.729293  0.703704  495.000000\n",
       "accuracy       0.692929  0.692929  0.692929    0.692929\n",
       "macro avg      0.693955  0.692929  0.692523  990.000000\n",
       "weighted avg   0.693955  0.692929  0.692523  990.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BPEmb model \n",
    "report = classification_report(y_test, preds_bpemb, output_dict=True)\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text, model, tokenizer, max_length=100):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=max_length)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def get_hidden_states(text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    output = model(input_ids)\n",
    "    return output.hidden_states\n",
    "\n",
    "def generate_all(text, model, tokenizer, max_length, num_beams, no_reapeat_ngrams, temperature, top_k, top_p):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    greedy_output = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "    beam_search_output = model.generate(input_ids, max_length=max_length, do_sample=True, num_beams=num_beams)\n",
    "    n_grams_output = model.generate(input_ids, max_length=max_length, no_repeat_ngram_size=no_reapeat_ngrams, num_beams=num_beams)\n",
    "    sample_output = model.generate(input_ids, max_length=max_length, do_sample=True, temperature=temperature)\n",
    "    top_k_otput = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=top_k)\n",
    "    top_p_output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=top_k, top_p=top_p)\n",
    "\n",
    "    output_lst = [greedy_output, beam_search_output, n_grams_output, sample_output, top_k_otput, top_p_output]\n",
    "    decoded_samples = [tokenizer.decode(g[0], skip_special_tokens=True) for g in output_lst]\n",
    "\n",
    "    return decoded_samples\n",
    "\n",
    "def generate_top_p(text, model, tokenizer, max_length, top_p, top_k):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=max_length, do_sample=True,top_k=top_k, top_p=top_p)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_all(\"The weather is\", model, tokenizer, 50, 5, 2, 0.7, 50, 0.95)\n",
    "print(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0301,  0.3668,  0.0901,  ..., -0.2221,  0.1273, -0.1497],\n",
       "         [ 0.5815,  0.2135,  0.1955,  ...,  0.4937,  0.0897, -0.2369],\n",
       "         [ 0.2250,  0.5953, -0.3460,  ...,  0.3857, -0.0740,  0.1617]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate_top_p(\"The weather is\", model, tokenizer, 50, 0.95, 50)\n",
    "get_hidden_states(\"The weather is\", model, tokenizer)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode('I was meaning to', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_beams=5)\n",
    "print(\"Beam Search Output:\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "output = model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size=2)\n",
    "print(\"N-Gram Penalty on Beam Search Output:\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_output = model.generate(input_ids, max_length=50, do_sample=True)\n",
    "print(\"Sampling Output:\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True, do_sample=True))\n",
    "\n",
    "greedy_output = model.generate(input_ids, max_length=50, do_sample=True, temperature=10.)\n",
    "print(\"Sampling Output:\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True, do_sample=True))\n",
    "\n",
    "greedy_output = model.generate(input_ids, max_length=50, do_sample=True, temperature=0.5)\n",
    "print(\"Sampling Output:\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True, do_sample=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ac075dbf107ca10f05bcc388d88f275addd2a735b233d21443c8ee15d0b537"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
